# Домашнее задание 1

Знакомьтесь, Zwitter -- новая, амбициозная социальная сеть.
Чем именно она отличается от существующих -- это вопрос, на который еще предстоит дать ответ,
но одно известно точно: опытные основатели-стартапщики умудрились уже каким-то образом
привлечь пользователей в эту социальную сеть, и им теперь нужна ваша помощь
в том, чтобы разобраться, кто же эти самые привлеченные пользователи.

## Что надо делать?

Вам необходимо решить следующие задачи:

  * наладить сбор логов веб-серверов социальной сети и их сохранение в HDFS,
  * наладить ежедневный расчет ключевых метрик и показателей,
  * предоставить доступ к рассчитанным данным через HTTP API.

Ниже вы можете найти более подробную информацию по следующим вопросам:

  * [Требования](#Требования)
  * [Критерии сдачи задания](#Критерии-сдачи-задания)
  * [Процесс сдачи задания](#Процесс-сдачи-задания)
  * [Исходные данные](#Исходные-данные)
  * [Рассчитываемые метрики](#Рассчитываемые-метрики)
  * [Спецификация HTTP API](#Спецификация-http-api)
  * [Дополнительные комментарии](#Дополнительные-комментарии)

## Требования

Ваше решение вышеописанных задач должно удовлетворять следующим требованиям:

  * загружаемые логи должны располагаться в HDFS по пути `/user/USER/zwitter_logs/`, где `USER` -- ваш логин;
  * загружаемый лог за конкретную дату должен храниться в файле с именем `access.log.YYYY-MM-DD`, где `YYYY-MM-DD` -- конкретная дата;
  * в HDFS необходимо хранить логи за последние 21 день; логи старше 21 дня необходимо удалять из HDFS;
  * вычисленные данные должны быть готовы к 9 утра следующего дня (к примеру, результаты за 25.09
    должны быть готовы к 09:00 26.09); готовность вычисленных данных определяется наличием
    исходных данных в HDFS и доступностью вычисленных метрик через HTTP API;
  * время ответа HTTP API не должно превышать 10 секунд;
  * запрещается запускать MapReduce-задачи как реакцию на HTTP-запрос;
  * ваш процесс сбора и расчета должен стабильно работать начиная с момента сдачи задания
    и до окончания курса, при этом ваше решение _не должно_ терять просчитанные данные за
    прошедшие дни (в том числе и после удаления исходных данных из HDFS).

## Критерии сдачи задания

Задание засчитывается как сданное (и вы получаете одного попугая), если:

  1. До **14-го октября 23:59** включительно (промежуточный дедлайн) реализована загрузка логов в HDFS и их ротация. Специальным образом сдавать этот пункт не нужно.
  2. До **18-го октября 23:59** включительно (финальный дедлайн) реализован расчет хотя бы _трех_ метрик первой группы и хотя бы _одной_ метрики второй группы, и результаты расчетов доступны через HTTP API. Ваше решение должно быть зарегистрировано в системе проверки.
  3. В период **с 15 октября по 1 ноября** включительно происходит проверка состония HDFS на наличие, целостность и ротирование логов за период с 1 октября по 1 ноября включительно.
  4. В период **с 19 октября по 1 ноября** включительно ваше решение ежедневно около 9:00 опрашивается по HTTP API о ключевых метриках за период с 1 октября по 1 ноября включительно.
  5. Задание считается сданным, если ваше решение корректно работает с 19 октября по 1 ноября (допускается 2 дня "неполадок"). Корректность работы определяется корректным состоянием HDFS, а также корректностью вычисления метрик.

Дополнительных попугаев в этом задании можно заработать следующими способами:

  * реализация одной дополнительной метрики первой группы и одной дополнительной метрики второй группы
    конвертируется в одного попугая; расчет засчитываеся, как только ваше решение в течение 2-х недель выдает
    по HTTP API корректные данные (допускается 2 дня "неполадок");
  * если ваше решение корректно работает в течение 45 дней (допускается 7 дней "неполадок"), то вы получаете одного попугая.
  * суммарно за это задание можно получить не более трех дополнительных попугаев.

## Процесс сдачи задания

Для самопроверки и сдачи вашего решения вам необходимо будет использовать веб-интерфейс Zwitter,
доступный на порту `8888` машины `hadoop2-00.yandex.ru` (NB: для доступа к веб-интерфейсу
вам необходимо пробросить `8888`-й порт на локальную машину, аналогично веб-интерфейсу Hadoop).

Для самопроверки вашего решения используйте страницу по адресу `http://127.0.0.1:8888/ysda/hw1`, где
вы можете указать порт, на котором работает ваше HTTP API, и диапазон дат. При нажатии на кнопку "Preview"
будет выполнен тестовый запрос к вашему решению, проверена корректность ответа (структура ответа и
типы возвращаемых значений, но не сами значения), и произведена визуализация ответа вашего решения.

Для сдачи вашего решения вам необходимо зарегистрироваться в системе по адресу `http://127.0.0.1:8888/ysda/register`,
и далее на странице `http://127.0.0.1:8888/ysda/hw1` указать порт и нажать на кнопку "Submit".
При этом указанный вами порт будет сохранен в системе и будет использован при последующих
ежедневных проверках корректности выполнения домашнего задания. Убедитесь, что после нажатия на кнопку "Submit"
в интерфейсе появилась надпись "_You have submitted your home assignment to be checked on port NNN_".

## Исходные данные

На машине `hadoop2-00.yandex.ru` в каталоге `/home/sandello/logs/` веб-сервера социальной сети
сохраняют логи. Логи старше 3-х дней автоматически удаляются (у вас есть 3 дня, чтобы сохранить их в HDFS!). 

Ниже приведен пример состояния директории с логами на дату 26 сентября 2015 года: 

```
access.log.2015-09-26  <-- Текущий записываемый лог
access.log.2015-09-25  <-- Лог за 25 сентября 2015 года
access.log.2015-09-24  <-- Лог за 24 сентября 2015 года
access.log.2015-09-23  <-- Лог за 23 сентября 2015 года
...
```

Пример записей в логе:

```
195.206.123.39 - - [24/Sep/2015:12:32:53 +0400] "GET /id18222 HTTP/1.1" 200 10703 "http://bing.com/" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36"
176.62.191.48 - - [24/Sep/2015:12:32:53 +0400] "GET /id81715 HTTP/1.1" 200 32343 "-" "OFM search_robot .*google.*  (compatible; )"
193.9.247.243 - - [24/Sep/2015:12:32:53 +0400] "GET /id79304 HTTP/1.1" 200 29671 "http://twitter.com/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/537.8 (KHTML, like Gecko) Chrome/23.0.1255.0 Safari/537.8"
194.196.94.215 - - [24/Sep/2015:12:32:53 +0400] "GET / HTTP/1.1" 200 32598 "http://yandex.ru/yandsearch" "Mozilla/5.0 (Linux; U; Android 4.2.2; de-de; HTC_One/2.24.111.5 Build/JDQ39) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30"
176.120.29.168 - - [24/Sep/2015:12:32:56 +0400] "GET /id50192 HTTP/1.1" 200 20065 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.99 Safari/537.36"
79.132.115.64 - - [24/Sep/2015:12:32:56 +0400] "GET /id49582 HTTP/1.1" 200 28244 "-" "Mozilla/5.0 (Windows NT 5.1; U; de; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 Opera 11.00"
```

Каждый лог преставляет из себя файл формата [access.log](http://httpd.apache.org/docs/2.0/logs.html#accesslog).
Каждая строка лога представляет собой запись, состояющую из нескольких полей, разделенных пробелом.
Строковые поля записываются в кавычках; внутренние кавычки строк экранируются символом `\`.

Каждая запись содержит следующие поля (на примере первой строки из вышеприведенного фрагмента):

  * IP-адрес пользователя (`195.206.123.39`),
  * Далее идут два неиспользуемых в нашем случае поля (`-` и `-`),
  * Время запроса (`[24/Sep/2015:12:32:53 +0400]`),
  * Строка запроса (`"GET /id18222 HTTP/1.1"`),
  * HTTP-код ответа (`200`),
  * Размер ответа (`10703`),
  * Реферер (источник перехода; `"http://bing.com/"`),
  * Идентификационная строка браузера (User-Agent; `"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36"`).

Считаем, что пользователь идентифицируется IP-адресом. Пользователи с различными IP-адресами считаются разными.

Из каждой записи можно извлечь информацию о браузере пользователя. Вам предлагается придумать набор эвристик,
позволяющих по User-Agent опознать браузер пользователя. Для упрощения задачи ответ нужно выбрать среди множества
Chrome, Yandex Browser, Firefox, Safari, Internet Explorer, Other. В приведенном выше примере правильные ответы --
Chrome, Other, Chrome, Other, Chrome, Firefox.

Также по IP-адресу пользователя можно восстановить его местоположение. В директории
`/home/sandello/data` лежат две базы IP2LOCATION.

В файле `IP2LOCATION-LITE-DB1.CSV` закодирована информация о соответствии стран и IP-адресов;
в файле `IP2LOCATION-LITE-DB5.CSV` -- более точная гео-информация.

Пример записей:

```
# IP2LOCATION-LITE-DB1.CSV
"34643712","34644479","RU","Russian Federation"
"34644480","34644991","DE","Germany"
"34644992","34645503","US","United States"
"34645504","34646015","NL","Netherlands"
"34646016","34646271","RU","Russian Federation"
"34646272","34646527","NL","Netherlands"
```

```
# IP2LOCATION-LITE-DB5.CSV
"34643712","34644479","RU","Russian Federation","Moscow City","Moscow","55.752220","37.615560"
"34644480","34644735","DE","Germany","Bayern","Nuremberg","49.447780","11.068330"
"34644736","34644991","DE","Germany","Nordrhein-Westfalen","Remscheid","51.179830","7.192500"
"34644992","34645503","US","United States","California","Los Angeles","34.052230","-118.243680"
"34645504","34646015","NL","Netherlands","Noord-Holland","Amsterdam","52.374030","4.889690"
"34646016","34646271","RU","Russian Federation","Moscow City","Moscow","55.752220","37.615560"
```

Каждая строка состоит из нескольких полей:

  * нижняя граница диапазона IP-адресов (`34643712`),
  * верхняя граница диапазона IP-адресов (`34644479`),
  * код страны (`RU`),
  * полное название страны (`Russian Federation`),
  * регион (`Moscow City`),
  * город (`Moscow`),
  * широта (`55.752220`),
  * долгота (`37.615560`).

Перевод IP-адреса между численным представлением и строковым осуществляется через
кодирование/декодирование отдельных байт численного представления. Каждый IP-адрес
в численном представлении кодируется 32-битным числом, которое можно интерпретировать
как набор из 4 байт.

Пример (на основе первой записи из приведенного выше фрагмента базы):

```python
# Нижняя граница
dec = 34643712
byte_0 = (dec >> 24) & 0xff  # 2
byte_1 = (dec >> 16) & 0xff  # 16
byte_2 = (dec >>  8) & 0xff  # 159
byte_3 = (dec >>  0) & 0xff  # 0
txt = ".".join(map(str, [byte_0, byte_1, byte_2, byte_3]))  # "2.16.159.0"

# Верхняя граница
dec = 34644479
byte_0 = (dec >> 24) & 0xff  # 2
byte_1 = (dec >> 16) & 0xff  # 16
byte_2 = (dec >>  8) & 0xff  # 161
byte_3 = (dec >>  0) & 0xff  # 255
txt = ".".join(map(str, [byte_0, byte_1, byte_2, byte_3]))  # "2.16.161.255"

# Обратный перевод
txt = "2.16.160.128"
byte_0, byte_1, byte_2, byte_3 = map(int, txt.split("."))  # 2, 16, 160, 128
dec = byte_0 << 24 | byte_1 << 16 | byte_2 << 8 | byte_3 << 0  # 34644096
```

## Рассчитываемые метрики

В рамках данного задания вам по дневному логу необходимо посчитать ключевые метрики для веб-сайта социальной сети.

**Все** нижеприведенные метрики расчитываются только по успешным (HTTP-код 200) запросам к сайту.
Неуспешные запросы стоит игнорировать (обычно такие запросы порождены сканерами, ищущими известные уязвимости
в веб-сайтах).

Метрики условно делятся на две группы -- попроще и посложнее.

Метрики первой группы:

  * `total_hits` -- Суммарное количество запросов к сайту.
  * `total_users` -- Суммарное количество уникальных пользователей. Пользователь идентифицируется IP-адресом.
  * `total_sessions` -- Суммарное количество сессий. Сессией считается последовательность запросов от одного пользователя
    с разницей по времени между последовательными запросами не более 30 минут. 
  * `top_10_pages` -- 10 самых посещаемых страниц сайта.
  * `average_session_time` -- Среднее время сессии в секундах (дробное число).
  * `average_session_length` -- Средняя длина сессии (количество посещенных страниц в течение одной сессии; дробное число).

Метрики второй группы:

  * `new_users` -- Количество новых пользователей. Пользователь считается новым в день X,
    если он посетил социальную сеть Zwitter в день X, но не посещал ее в течение последних двух недель
    (14 дней не включая день X).
  * `lost_users` -- Количество потерянных пользоватеей. Пользователь считается потерянным в день X,
    если он _не_ посещал социальную сеть Zwitter в день X, а также в течение последних двух недель
    (14 дней не включая день X), но посещал социальную сеть до этого.
  * `users_by_browser` -- Количество пользователей в разбивке по браузерам.
  Способ определения браузера описан в секции "Исходные данные". Требуется, чтобы в группе Other было не более 3% пользователей.
  * `users_by_country` -- Количество пользователей в разбивке по странам.
  Способ определения страны описан в секции "Исходные данные".
  * `facebook_promo_conversion` -- Отношение количества пользователей, пришедших на социальную сеть из Facebook
  (первый переход в социальную сеть осуществлен с Facebook) и посетивших страницу `/promo`
  (необязательно в рамках одной сессии), к суммарному количеству пользователей, пришедших в социальную сеть Zwitter
  из Facebook (дробное число).


## Спецификация HTTP API

Ваше решение должно уметь отвечать на запросы типа `GET` по URI `/api/hw1`; 
в параметрах запроса указывается начальная дата `start_date` и конечная дата `end_date`,
за которые необходимо вернуть данные. Даты указываются в формате `YYYY-MM-DD`.

В ответе вам необходимо вернуть JSON-документ, ключами которого являются даты
в запрашиваемом диапазоне, а значениями -- JSON-документы с рассчитываемыми метриками
(указывайте только те метрики, что вы реально рассчитываете).

Пример запроса:

```
GET /api/hw1?start_date=2015-10-01&end_date=2015-10-05
```

Пример ответа:
```json
{
  "2015-10-01": {
    "total_hits": 1000,
    "total_users": 100,
    "total_sessions": 200,
    "top_10_pages": [
      "/", "/id1", "/id2", "/id3", "/id4", "/id5", "/id6", "/id7", "/id8", "/id9"
    ],
    "average_session_time": 300.0,
    "average_session_length": 5.0,
    "new_users": 10,
    "lost_users": 10,
    "users_by_browser": {
      "Chrome": 20,
      "Yandex Browser": 20,
      "Firefox": 20,
      "Safari": 10,
      "Internet Explorer": 10,
      "Other": 10,
    },
    "users_by_country": {
      "Russian Federation": 100
    },
    "facebook_promo_conversion": 0.05
  },
  "2015-10-02": { ... },
  "2015-10-03": { ... },
  "2015-10-04": { ... },
  "2015-10-05": { ... }
}
```

Пример ответа только с метриками `total_hits` и `total_users`:
```json
{
  "2015-10-01": {
    "total_hits": 1000,
    "total_users": 100
  },
  "2015-10-02": { ... },
  "2015-10-03": { ... },
  "2015-10-04": { ... },
  "2015-10-05": { ... }
}
```

Для быстрого старта вы можете воспользоваться доступным [шаблоном HTTP API](./example.py).

## Дополнительные комментарии

  * Для периодического запуска процессов используйте `cron` ([[1]](https://ru.wikipedia.org/wiki/Cron), [[2]](http://help.ubuntu.ru/wiki/cron)).
  * Для того, чтобы запущенная вами программа не была остановлена при отключении ssh, используйте `screen` или `tmux` ([[1]](http://habrahabr.ru/post/126996/)).
  * Изучите (административный) веб-интерфейс Zwitter: он может быть полезен не только при сдаче задания,
    но и при отладке вашего сервиса.
  * Процесс ротации старых логов в HDFS совместите с загрузкой новых данных:
    удаляйте старые данные после успешной загрузки новых.
  * Настройте запуск процесса загрузки логов ежечасно. При этом работу загрузчика следует организовать так, чтобы он
    сравнивал директорию с логами на локальной машине и директорию с логами в HDFS и принимал решение о загрузке новых логов.
    Такая организация работы загрузчика поможет реализовать его работу устойчивой к временным сбоям.
  * Подумайте, где вы будете хранить результаты расчета? Как самый простой вариант -- сохраняйте результаты
    в файл с именем, соответствующим дате, за которую был произведен расчет. Для сохранности результатов
    на случай выпадения головной машины стоит использовать HDFS.
  * Если вы хотите вычислить какую-то дополнительную метрику, которую мы не описали, напишите нам, вероятно,
    мы ее добавим в список рассчитываемых метрик. Может, вычисление этой метрики будет интересно не только вам.

## Часто задаваемые вопросы

  * **Можно ли менять решение после дедлайна?** Да. Причины для этого могут быть следующие: по результатам автопроверок вы видите, что ваша метрика не засчитывается / сломалась, и вы хотите ее исправить; или вы реализовали новую метрику, и хотите подключить ее к автопроверкам, чтобы заработать дополнительных попугаев.
  
